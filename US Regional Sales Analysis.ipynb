{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2cbf6f",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93050b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183383a",
   "metadata": {},
   "source": [
    "# 2. Loading the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65aceaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderNumber          object\n",
       "Sales Channel        object\n",
       "WarehouseCode        object\n",
       "ProcuredDate         object\n",
       "OrderDate            object\n",
       "ShipDate             object\n",
       "DeliveryDate         object\n",
       "CurrencyCode         object\n",
       "_SalesTeamID          int64\n",
       "_CustomerID           int64\n",
       "_StoreID              int64\n",
       "_ProductID            int64\n",
       "Order Quantity        int64\n",
       "Discount Applied    float64\n",
       "Unit Cost            object\n",
       "Unit Price           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('US_Regional_Sales_Data.csv')  # https://www.kaggle.com/datasets/talhabu/us-regional-sales-data\n",
    "data.head(2)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8802f",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e019b4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderNumber                 object\n",
       "Sales Channel               object\n",
       "WarehouseCode               object\n",
       "ProcuredDate        datetime64[ns]\n",
       "OrderDate           datetime64[ns]\n",
       "ShipDate            datetime64[ns]\n",
       "DeliveryDate        datetime64[ns]\n",
       "CurrencyCode                object\n",
       "_SalesTeamID                 int64\n",
       "_CustomerID                  int64\n",
       "_StoreID                     int64\n",
       "_ProductID                   int64\n",
       "Order Quantity             float64\n",
       "Discount Applied           float64\n",
       "Unit Cost                  float64\n",
       "Unit Price                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date columns to datetime objects\n",
    "date_columns = ['ProcuredDate', 'OrderDate', 'ShipDate', 'DeliveryDate']\n",
    "for col in date_columns:\n",
    "    data[col] = pd.to_datetime(data[col], dayfirst=True)\n",
    "\n",
    "# Remove commas and convert numerical columns to appropriate types\n",
    "numeric_columns = ['Order Quantity', 'Discount Applied', 'Unit Cost', 'Unit Price']\n",
    "data[numeric_columns] = data[numeric_columns].replace({',': ''}, regex=True).astype(float)\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f24bc",
   "metadata": {},
   "source": [
    "# 4. Data Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef8168",
   "metadata": {},
   "source": [
    "Time Series Analysis - Sales Trends Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('OrderDate', inplace=True)\n",
    "data.resample('M').sum()['Unit Price'].plot()  # Monthly sales trends\n",
    "plt.title('Monthly Sales Trends')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1125de",
   "metadata": {},
   "source": [
    "Sales Channel Comparison - Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ad2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Sales Channel', y='Unit Price', data=data)\n",
    "plt.title('Sales Channel Comparison')\n",
    "plt.ylabel('Average Unit Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df488777",
   "metadata": {},
   "source": [
    "Product Analysis - Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sales = data.groupby('_ProductID')['Unit Price'].sum()\n",
    "plt.pie(product_sales, labels=product_sales.index, autopct='%1.1f%%')\n",
    "plt.title('Product Sales Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4929537d",
   "metadata": {},
   "source": [
    "Discount Analysis - Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Discount Applied', y='Unit Price', data=data)\n",
    "plt.title('Discount Analysis')\n",
    "plt.xlabel('Discount Applied')\n",
    "plt.ylabel('Unit Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fc0c1",
   "metadata": {},
   "source": [
    "# 5. Feature Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9643bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date-based Features:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "data['ProcuredDate'] = pd.to_datetime(data['ProcuredDate'], dayfirst=True)\n",
    "data['OrderDate'] = pd.to_datetime(data['OrderDate'], dayfirst=True)\n",
    "data['ShipDate'] = pd.to_datetime(data['ShipDate'], dayfirst=True)\n",
    "data['DeliveryDate'] = pd.to_datetime(data['DeliveryDate'], dayfirst=True)\n",
    "\n",
    "# Extract day of the week, month, quarter, and year from date columns\n",
    "data['ProcuredDayOfWeek'] = data['ProcuredDate'].dt.dayofweek\n",
    "data['ProcuredMonth'] = data['ProcuredDate'].dt.month\n",
    "data['ProcuredQuarter'] = data['ProcuredDate'].dt.quarter\n",
    "data['ProcuredYear'] = data['ProcuredDate'].dt.year\n",
    "\n",
    "data['OrderDayOfWeek'] = data['OrderDate'].dt.dayofweek\n",
    "data['OrderMonth'] = data['OrderDate'].dt.month\n",
    "data['OrderQuarter'] = data['OrderDate'].dt.quarter\n",
    "data['OrderYear'] = data['OrderDate'].dt.year\n",
    "\n",
    "data['ShipDayOfWeek'] = data['ShipDate'].dt.dayofweek\n",
    "data['ShipMonth'] = data['ShipDate'].dt.month\n",
    "data['ShipQuarter'] = data['ShipDate'].dt.quarter\n",
    "data['ShipYear'] = data['ShipDate'].dt.year\n",
    "\n",
    "data['DeliveryDayOfWeek'] = data['DeliveryDate'].dt.dayofweek\n",
    "data['DeliveryMonth'] = data['DeliveryDate'].dt.month\n",
    "data['DeliveryQuarter'] = data['DeliveryDate'].dt.quarter\n",
    "data['DeliveryYear'] = data['DeliveryDate'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59eb7c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OrderNumber Sales Channel WarehouseCode ProcuredDate  OrderDate   ShipDate  \\\n",
      "0  SO - 000101      In-Store  WARE-UHY1004   2017-12-31 2018-05-31 2018-06-14   \n",
      "1  SO - 000102        Online  WARE-NMK1003   2017-12-31 2018-05-31 2018-06-22   \n",
      "2  SO - 000103   Distributor  WARE-UHY1004   2017-12-31 2018-05-31 2018-06-21   \n",
      "3  SO - 000104     Wholesale  WARE-NMK1003   2017-12-31 2018-05-31 2018-06-02   \n",
      "4  SO - 000105   Distributor  WARE-NMK1003   2018-04-10 2018-05-31 2018-06-16   \n",
      "\n",
      "  DeliveryDate CurrencyCode  _SalesTeamID  _CustomerID  ...  ShipMonth  \\\n",
      "0   2018-06-19          USD             6           15  ...          6   \n",
      "1   2018-07-02          USD            14           20  ...          6   \n",
      "2   2018-07-01          USD            21           16  ...          6   \n",
      "3   2018-06-07          USD            28           48  ...          6   \n",
      "4   2018-06-26          USD            22           49  ...          6   \n",
      "\n",
      "   ShipQuarter  ShipYear  DeliveryDayOfWeek  DeliveryMonth  DeliveryQuarter  \\\n",
      "0            2      2018                  1              6                2   \n",
      "1            2      2018                  0              7                3   \n",
      "2            2      2018                  6              7                3   \n",
      "3            2      2018                  3              6                2   \n",
      "4            2      2018                  1              6                2   \n",
      "\n",
      "   DeliveryYear  Revenue   Profit  DiscountRatio  \n",
      "0          2018   9815.5  4809.60       0.000038  \n",
      "1          2018  11818.8  1772.82       0.000019  \n",
      "2          2018   1775.5   994.28       0.000028  \n",
      "3          2018  18599.2  6881.68       0.000032  \n",
      "4          2018  14579.2  2770.08       0.000055  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sales Performance Metrics:\n",
    "\n",
    "# Calculate sales performance metrics\n",
    "\n",
    "data['Revenue'] = (data['Unit Price'] * data['Order Quantity']).astype(float)\n",
    "data['Profit'] = (data['Revenue'] - (data['Unit Cost'] * data['Order Quantity'])).astype(float)\n",
    "data['DiscountRatio'] = (data['Discount Applied'] / data['Unit Price']).astype(float)\n",
    "\n",
    "# Display the updated dataset with the new metrics\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e732e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderNumber                  object\n",
       "Sales Channel                object\n",
       "WarehouseCode                object\n",
       "ProcuredDate         datetime64[ns]\n",
       "OrderDate            datetime64[ns]\n",
       "ShipDate             datetime64[ns]\n",
       "DeliveryDate         datetime64[ns]\n",
       "CurrencyCode                 object\n",
       "_SalesTeamID                  int64\n",
       "_CustomerID                   int64\n",
       "_StoreID                      int64\n",
       "_ProductID                    int64\n",
       "Order Quantity              float64\n",
       "Discount Applied            float64\n",
       "Unit Cost                   float64\n",
       "Unit Price                  float64\n",
       "ProcuredDayOfWeek             int64\n",
       "ProcuredMonth                 int64\n",
       "ProcuredQuarter               int64\n",
       "ProcuredYear                  int64\n",
       "OrderDayOfWeek                int64\n",
       "OrderMonth                    int64\n",
       "OrderQuarter                  int64\n",
       "OrderYear                     int64\n",
       "ShipDayOfWeek                 int64\n",
       "ShipMonth                     int64\n",
       "ShipQuarter                   int64\n",
       "ShipYear                      int64\n",
       "DeliveryDayOfWeek             int64\n",
       "DeliveryMonth                 int64\n",
       "DeliveryQuarter               int64\n",
       "DeliveryYear                  int64\n",
       "Revenue                     float64\n",
       "Profit                      float64\n",
       "DiscountRatio               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a58353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Encodings:\n",
    "\n",
    "# One-hot encode the 'Sales Channel' and 'WarehouseCode' columns\n",
    "data = pd.get_dummies(data, columns=['Sales Channel', 'WarehouseCode'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6af818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Since Previous Order:\n",
    "\n",
    "# Sort the data by 'CustomerID' and 'OrderDate'\n",
    "data.sort_values(['_CustomerID', 'OrderDate'], inplace=True)\n",
    "\n",
    "# Calculate time since the previous order for each customer\n",
    "data['TimeSincePreviousOrder'] = data.groupby('_CustomerID')['OrderDate'].diff().dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e04dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Aggregated Features:\n",
    "\n",
    "# Calculate mean and total sales for each customer\n",
    "customer_sales = data.groupby('_CustomerID')['Revenue'].agg(['mean', 'sum']).reset_index()\n",
    "customer_sales.rename(columns={'mean': 'AvgCustomerSales', 'sum': 'TotalCustomerSales'}, inplace=True)\n",
    "\n",
    "# Merge aggregated features back to the original dataset\n",
    "data = data.merge(customer_sales, on='_CustomerID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311b8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction Features:\n",
    "\n",
    "data['Interaction'] = data['Order Quantity'] * data['Discount Applied']\n",
    "data['DiscountToCostRatio'] = data['Discount Applied'] / data['Unit Cost']\n",
    "data['DiscountToQuantityRatio'] = data['Discount Applied'] / data['Order Quantity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c2aa88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical Features:\n",
    "\n",
    "data['CumulativeRevenue'] = data.groupby(['_ProductID'])['Revenue'].cumsum()\n",
    "data['CumulativeProfit'] = data.groupby(['_CustomerID'])['Profit'].cumsum()\n",
    "data['CumulativeQuantity'] = data.groupby(['_ProductID', '_CustomerID'])['Order Quantity'].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d61bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration Feature\n",
    "\n",
    "data['OrderToShipDuration'] = (data['ShipDate'] - data['OrderDate']).dt.days\n",
    "data['OrderToDeliveryDuration'] = (data['DeliveryDate'] - data['OrderDate']).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf9578bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Lifetime Features:\n",
    "\n",
    "customer_first_order = data.groupby('_CustomerID')['OrderDate'].min()\n",
    "customer_last_order = data.groupby('_CustomerID')['OrderDate'].max()\n",
    "data['CustomerLifetime'] = (customer_last_order - customer_first_order).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27600506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdbaad25",
   "metadata": {},
   "source": [
    "# 6. Data Modeling - Price Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21bb7fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Root Mean Squared Error (RMSE) \n",
      "Linear Regression RMSE: 568.1500245030115\n",
      "Random Forest Regression RMSE: 562.0114244321398\n",
      "Neural Network Regression RMSE: 569.6856231746407\n",
      " \n",
      "   Coefficient of Determination (R-squared) \n",
      "Linear Regression R-squared: 0.8871029275211023\n",
      "Random Forest R-squared: 0.8895293501633315\n",
      "Neural Network R-squared: 0.8864918252685968\n",
      " \n",
      "   Mean Absolute Error (MAE) \n",
      "Linear Regression MAE: 410.68697339236445\n",
      "Random Forest MAE: 370.73626398890184\n",
      "Neural Network MAE: 400.1836662251424\n",
      " \n",
      "  Mean Squared Error (MSE)\n",
      "Linear Regression MSE: 322794.45034277264\n",
      "Random Forest MSE: 315856.84119224286\n",
      "Neural Network MSE: 324541.7092518787\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhavi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = data[['Order Quantity', 'Discount Applied', 'Unit Cost']]\n",
    "y = data['Unit Price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Random Forest Regression\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Neural Network Regression\n",
    "nn_model = MLPRegressor(random_state=42)\n",
    "nn_model.fit(X_train, y_train)\n",
    "nn_pred = nn_model.predict(X_test)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"  Root Mean Squared Error (RMSE) \")\n",
    "print(\"Linear Regression RMSE:\", mean_squared_error(y_test, lr_pred, squared=False))\n",
    "print(\"Random Forest Regression RMSE:\", mean_squared_error(y_test, rf_pred, squared=False))\n",
    "print(\"Neural Network Regression RMSE:\", mean_squared_error(y_test, nn_pred, squared=False))\n",
    "print(\" \")\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R-squared\n",
    "r2_lr = r2_score(y_test, lr_pred)\n",
    "r2_rf = r2_score(y_test, rf_pred)\n",
    "r2_nn = r2_score(y_test, nn_pred)\n",
    "\n",
    "print(\"   Coefficient of Determination (R-squared) \")\n",
    "print(\"Linear Regression R-squared:\", r2_lr)\n",
    "print(\"Random Forest R-squared:\", r2_rf)\n",
    "print(\"Neural Network R-squared:\", r2_nn)\n",
    "print(\" \")\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_lr = mean_absolute_error(y_test, lr_pred)\n",
    "mae_rf = mean_absolute_error(y_test, rf_pred)\n",
    "mae_nn = mean_absolute_error(y_test, nn_pred)\n",
    "\n",
    "print(\"   Mean Absolute Error (MAE) \")\n",
    "print(\"Linear Regression MAE:\", mae_lr)\n",
    "print(\"Random Forest MAE:\", mae_rf)\n",
    "print(\"Neural Network MAE:\", mae_nn)\n",
    "print(\" \")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_lr = mean_squared_error(y_test, lr_pred)\n",
    "mse_rf = mean_squared_error(y_test, rf_pred)\n",
    "mse_nn = mean_squared_error(y_test, nn_pred)\n",
    "\n",
    "print(\"  Mean Squared Error (MSE)\")\n",
    "print(\"Linear Regression MSE:\", mse_lr)\n",
    "print(\"Random Forest MSE:\", mse_rf)\n",
    "print(\"Neural Network MSE:\", mse_nn)\n",
    "print(\" \")\n",
    "\n",
    "# Random Forest is the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2ee36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5085d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'OrderDate' to datetime\n",
    "data['OrderDate'] = pd.to_datetime(data['OrderDate'], dayfirst=True)\n",
    "\n",
    "# Set 'OrderDate' as the index\n",
    "data.set_index('OrderDate', inplace=True)\n",
    "\n",
    "# Resample and sum 'Unit Price' on a monthly basis\n",
    "monthly_sales = data['Unit Price'].resample('M').sum()\n",
    "\n",
    "# Plot the monthly sales trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_sales.plot()\n",
    "plt.title('Monthly Sales Trends')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcddc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller # determing d value\n",
    "\n",
    "adf_result = adfuller(monthly_sales)\n",
    "print('ADF Statistic:', adf_result[0])\n",
    "print('p-value:', adf_result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fea3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# Calculate autocorrelation and partial autocorrelation values\n",
    "# Use a smaller value for nlags to avoid the error\n",
    "nlags = 15  # Adjust this value as needed\n",
    "acf_values = acf(monthly_sales, nlags=nlags)\n",
    "pacf_values = pacf(monthly_sales, nlags=nlags)\n",
    "\n",
    "# Plot ACF\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(211)\n",
    "plt.stem(acf_values)\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('ACF')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot PACF\n",
    "plt.subplot(212)\n",
    "plt.stem(pacf_values)\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('PACF')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0d14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe598fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model\n",
    "p= 6\n",
    "d= 0\n",
    "q= 5\n",
    "order = (p, d, q)  # Choose appropriate values for p, d, q\n",
    "model = sm.tsa.ARIMA(monthly_sales, order=order)\n",
    "results = model.fit()\n",
    "\n",
    "# Forecast future values\n",
    "forecast_steps = 12  # Forecast for 12 months ahead\n",
    "forecast = results.get_forecast(steps=forecast_steps)\n",
    "\n",
    "# Plot original data and forecasted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(monthly_sales, label='Actual')\n",
    "plt.plot(forecast.predicted_mean, label='Forecast', color='red')\n",
    "plt.fill_between(forecast.conf_int().index,\n",
    "                 forecast.conf_int()['lower Unit Price'],\n",
    "                 forecast.conf_int()['upper Unit Price'], color='pink', alpha=0.3)\n",
    "plt.title('Monthly Sales Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f89ec5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
